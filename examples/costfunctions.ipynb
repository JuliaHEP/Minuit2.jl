{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-squares fits\n",
    "\n",
    "A cost function for a general weighted least-squares fit (aka chi-square fit) is also included. In statistics this is called non-linear regression.\n",
    "\n",
    "In this case you need to provide a model that predicts the y-values as a function of the x-values and the parameters. The fit needs estimates of the y-errors. If those are wrong, the fit may be biased. If your data has errors on the x-values as well, checkout the tutorial about automatic differentiation, which includes an application of that to such fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Minuit2\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model(x, a, b) = a + b * x^2\n",
    "\n",
    "# Define the data and truth\n",
    "truth = 1, 2\n",
    "x = range(0, 1., 20)\n",
    "yt = model.(x, truth...)\n",
    "ye = 0.4 .* x.^5 .+ 0.1\n",
    "y = yt + ye .* randn(length(x))\n",
    "\n",
    "# Plot with error bars\n",
    "plot(x, y, yerr=ye, seriestype=:scatter, label=\"Data\")\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = LeastSquares(x, y, ye, model)\n",
    "m1 = Minuit(c, a=0, b=0)\n",
    "migrad!(m1)\n",
    "visualize(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function model2(xy, a, bx, by)\n",
    "    x, y = xy\n",
    "    return a + bx * x + by * y\n",
    "end\n",
    "\n",
    "function model2_grad(xy, a, bx, by)\n",
    "    x, y = xy\n",
    "    return [1, x, y]\n",
    "end\n",
    "\n",
    "# generate a regular grid in x and y\n",
    "xy = [(x,y) for x in range(-1.,1.,10) for y in range(-1.,1.,10)]\n",
    "\n",
    "# model truth \n",
    "zt = model2.(xy, 1, 2, 3)\n",
    "\n",
    "zerror = 1.\n",
    "z = zt .+ zerror .* randn(length(xy))\n",
    "\n",
    "scatter(xy, zcolor=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = LeastSquares(xy, z, zerror, model2)\n",
    "m2 = Minuit(c2, 0, 0, 0)\n",
    "migrad!(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate fits are difficult to check by eye. Here we use color to indicate the function value.\n",
    "\n",
    "To guarantee that plot of the function and the plot of the data use the same color scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(range(-1.,1.,100), range(-1.,1.,100), (x,y)->model2((x,y), m2.values...))\n",
    "scatter!(xy, zcolor=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the gradient in a multi-variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = LeastSquares(xy, z, zerror, model2, model_grad=model2_grad)\n",
    "m2 = Minuit(c2, 0, 0, 0)\n",
    "migrad!(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust least-squared\n",
    "The built-in least-squares function also supports robust fitting with an alternative loss functions. Builtin loss functions are:\n",
    "\n",
    "- linear (default): gives ordinary weighted least-squares\n",
    "- soft_l1: quadratic ordinary loss for small deviations (<< 1σ), linear loss for large deviations (>> 1σ), and smooth interpolation in between\n",
    "\n",
    "Let’s create one outlier and see what happens with ordinary loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.y[4] = 3.0   # Generate an outlier\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can mask the outlier temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = c.y .!= 3.0\n",
    "c.mask = mask\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.mask = nothing\n",
    "c.loss = :soft_l1\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
