{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions\n",
    "\n",
    "A quick guide on how to use the built-in cost functions.\n",
    "\n",
    "The Minuit2.jl package comes with few of common cost functions. Of course, you can write your own cost functions to use with Minuit2, but most of the cost function is always the same. What really varies is the statistical model which predicts the probability density as a function of the parameter values.\n",
    "\n",
    "We demonstrate each cost function on a standard example from high-energy physics, the fit of a peak over some smooth background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Minuit2\n",
    "using Distributions\n",
    "using FHist\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate our data by sampling from a Gaussian peak and from exponential background in the range 0 to 2. The original data is then binned. One can fit the original or the binned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = (0, 2)\n",
    "xdata = rand(Normal(1., 0.1), 1000)\n",
    "ydata = rand(Exponential(1.), length(xdata))\n",
    "xmix = vcat(xdata, ydata)\n",
    "xmix = xmix[(rng[1] .< xmix .< rng[2])]\n",
    "h = Hist1D(xmix, nbins=20)\n",
    "x = bincenters(h)\n",
    "y = bincounts(h)\n",
    "dy = sqrt.(y)\n",
    "plot(x, y, yerr=dy, seriestype=:scatter, label=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also generate some 2D data to demonstrate multivariate fits. In this case, a Gaussian along axis 1 and independently an exponential along axis 2. In this case, the distributions are not restricted to some range in x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = Hist2D((xdata, ydata), binedges=(range(rng..., 21), range(0., maximum(ydata), 6)))\n",
    "plot(h2)\n",
    "scatter!(xdata, ydata, markersize=2, color=:white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum-likelihood fits\n",
    "\n",
    "Maximum-likelihood fits are the state-of-the-art when it comes to fitting models to data. They can be applied to unbinned and binned data (histograms).\n",
    "\n",
    "Unbinned fits are the easiest to use, because no data binning is needed. They become slow when the sample size is large.\n",
    "Binned fits require you to appropriately bin the data. The binning has to be fine enough to retain all essential information. Binned fits are much faster when the sample size is large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbinned fit\n",
    "\n",
    "Unbinned fits are ideal when the data samples are not too large or very high dimensional. \n",
    "There is no need to worry about the appropriate binning of the data. Unbinned fits are inefficient \n",
    "when the samples are very large and can become numerically unstable, too. \n",
    "Binned fits are a better choice then.\n",
    "\n",
    "The cost function an unbinned maximum-likelihood fit is really simple, it is the sum of the \n",
    "logarithm of the pdf evaluated at each sample point (times -1 to turn maximization into minimization).\n",
    "You can easily write this yourself, but a naive implementation will suffer from instabilities \n",
    "when the pdf becomes locally zero. Our implementation mitigates the instabilities to some extent.\n",
    "To perform the unbinned fit you need to provide the pdf of the model, which must be vectorized (a Numpy ufunc). \n",
    "\n",
    "The pdf must be normalized, which means that the integral over the sample value range must be a \n",
    "constant for any combination of model parameters. The model pdf in this case is a linear combination \n",
    "of the normal and the exponential pdfs. The parameters are  (the weight),  and  of the normal distribution and  of the exponential. The cost function detects the parameter names.\n",
    "\n",
    "It is important to put appropriate limits on the parameters, so that the problem does not become mathematically undefined.\n",
    "\n",
    ",\n",
    ",\n",
    ".\n",
    "In addition, it can be beneficial to use , but it is not required. We use truncnorm and truncexpon, which are normalized inside the data range (0, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pdf(x, ζ, μ, σ, τ) = ζ * pdf(truncated(Normal(μ, σ), rng...),x) + (1 - ζ) * pdf(truncated(Exponential(τ), rng...), x)\n",
    "\n",
    "cost = UnbinnedNLL(xmix, my_pdf)\n",
    "m = Minuit(cost, ζ=0.5, μ=1, σ=0.5, τ=1,\n",
    "                 limit_ζ=(0, 1), limit_μ=(0, 2), limit_σ=(0, Inf), limit_τ=(0, Inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrad!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minos!(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate\n",
    "We can also fit a multivariate model to multivariate data. We pass model as a `logpdf` this time, which works well because the pdfs factorize. The package `Distributions.jl` provides directly the function `logpdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_logpdf(xy, μ, σ, τ)\n",
    "    x, y = xy\n",
    "    logpdf(Normal(μ, σ), x) + logpdf(Exponential(τ), y)\n",
    "end\n",
    "\n",
    "c = UnbinnedNLL(hcat(xdata, ydata), my_logpdf, log=true)\n",
    "m = Minuit(c, μ=1, σ=2, τ=2, limit_σ=(0,Inf), limit_τ=(0,Inf))\n",
    "migrad!(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned Fit\n",
    "Binned fits are computationally more efficient and numerically more stable when samples are large. The caveat is that one has to choose an appropriate binning. The binning should be fine enough so that the essential information in the original is retained. Using large bins does not introduce a bias, but the parameters have a larger-than-minimal variance.\n",
    "\n",
    "In this case, 50 bins are fine enough to retain all information. Using many bins is safe, since the maximum-likelihood method correctly takes Poisson statistics into account, which works even if bins have zero entries. Using more bins than necessary just increases the computational cost.\n",
    "\n",
    "Instead of a pdf, you need to provide a cdf for a binned fit (which must be vectorized)??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cdf(x, ζ, μ, σ, τ) = ζ * cdf(truncated(Normal(μ, σ), rng...),x) + (1 - ζ) * cdf(truncated(Exponential(τ), rng...), x)\n",
    "\n",
    "h = Hist1D(xmix, nbins=20)\n",
    "c = BinnedNLL(bincounts(h), binedges(h), my_cdf)\n",
    "m = Minuit(c, ζ=0.4, μ=0, σ=0.2, τ=2, limit_ζ=(0, 1), limit_σ=(0, Inf), limit_τ=(0, Inf))\n",
    "migrad!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the `cdf` is expensive to calculate. In this case, you can approximate taking the `pdf` evaluated at the center of the bin. This can be done with `use_pdf=:approximate` when defining the BinnedNNL cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pdf(x, ζ, μ, σ, τ) = ζ * pdf(truncated(Normal(μ, σ), rng...),x) + (1 - ζ) * pdf(truncated(Exponential(τ), rng...), x)\n",
    "\n",
    "c = BinnedNLL(bincounts(h), binedges(h), my_pdf, use_pdf=:approximate)\n",
    "m = Minuit(c, ζ=0.4, μ=0, σ=0.2, τ=2, limit_ζ=(0, 1), limit_σ=(0, Inf), limit_τ=(0, Inf))\n",
    "migrad!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-dimensional Binned fit\n",
    "Fitting a multidimensional histogram is easy. Since the `pdfs` in this example factorise, the cdf of the 2D model is the product of the cdfs along each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pdf2(xy, μ, σ, τ) = pdf(Normal(μ, σ),xy[1]) * pdf(Exponential(τ), xy[2])\n",
    "\n",
    "h2 = Hist2D((xdata, ydata), nbins=(20, 20))\n",
    "c = BinnedNLL(bincounts(h2), binedges(h2), my_pdf2, use_pdf=:approximate)\n",
    "m = Minuit(c, ζ=0.4, μ=1, σ=2, τ=2, limit_σ=(0, Inf), limit_τ=(0, Inf))\n",
    "migrad!(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-squares fits\n",
    "\n",
    "A cost function for a general weighted least-squares fit (aka chi-square fit) is also included. In statistics this is called non-linear regression.\n",
    "\n",
    "In this case you need to provide a model that predicts the y-values as a function of the x-values and the parameters. The fit needs estimates of the y-errors. If those are wrong, the fit may be biased. If your data has errors on the x-values as well, checkout the tutorial about automatic differentiation, which includes an application of that to such fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model(x, a, b) = a + b * x^2\n",
    "\n",
    "# Define the data and truth\n",
    "truth = 1, 2\n",
    "x = range(0, 1., 20)\n",
    "yt = model.(x, truth...)\n",
    "ye = 0.4 .* x.^5 .+ 0.1\n",
    "y = yt + ye .* randn(length(x))\n",
    "\n",
    "# Plot with error bars\n",
    "plot(x, y, yerr=ye, seriestype=:scatter, label=\"Data\")\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = LeastSquares(x, y, ye, model)\n",
    "m1 = Minuit(c, a=0, b=0)\n",
    "migrad!(m1)\n",
    "visualize(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function model2(xy, a, bx, by)\n",
    "    x, y = xy\n",
    "    return a + bx * x + by * y\n",
    "end\n",
    "\n",
    "function model2_grad(xy, a, bx, by)\n",
    "    x, y = xy\n",
    "    return [1, x, y]\n",
    "end\n",
    "\n",
    "# generate a regular grid in x and y\n",
    "xy = [(x,y) for x in range(-1.,1.,10) for y in range(-1.,1.,10)]\n",
    "\n",
    "# model truth \n",
    "zt = model2.(xy, 1, 2, 3)\n",
    "\n",
    "zerror = 1.\n",
    "z = zt .+ zerror .* randn(length(xy))\n",
    "\n",
    "scatter(xy, zcolor=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = LeastSquares(xy, z, zerror, model2)\n",
    "m2 = Minuit(c2, 0, 0, 0)\n",
    "migrad!(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate fits are difficult to check by eye. Here we use color to indicate the function value.\n",
    "\n",
    "To guarantee that plot of the function and the plot of the data use the same color scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(range(-1.,1.,100), range(-1.,1.,100), (x,y)->model2((x,y), m2.values...))\n",
    "scatter!(xy, zcolor=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the gradient in a multi-variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = LeastSquares(xy, z, zerror, model2, model_grad=model2_grad)\n",
    "m2 = Minuit(c2, 0, 0, 0)\n",
    "migrad!(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust least-squared\n",
    "The built-in least-squares function also supports robust fitting with an alternative loss functions. Builtin loss functions are:\n",
    "\n",
    "- linear (default): gives ordinary weighted least-squares\n",
    "- soft_l1: quadratic ordinary loss for small deviations (<< 1σ), linear loss for large deviations (>> 1σ), and smooth interpolation in between\n",
    "\n",
    "Let’s create one outlier and see what happens with ordinary loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.y[4] = 3.0   # Generate an outlier\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can mask the outlier temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = c.y .!= 3.0\n",
    "c.mask = mask\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.mask = nothing\n",
    "c.loss = :soft_l1\n",
    "migrad!(m1)\n",
    "visualize(m1)\n",
    "plot!(x, yt, label=\"Truth\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
